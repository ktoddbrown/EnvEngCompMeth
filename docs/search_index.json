[
["index.html", "Computational Methods for Environmental Engineers - Course Notes Why do we care about computational methods? 0.1 Other references", " Computational Methods for Environmental Engineers - Course Notes K Todd-Brown (ktoddbrown@ufl.edu) 9/28/2020 Why do we care about computational methods? Computational methods could be one of the most useful courses you have ever taken. As an engineer, scientist or technical staff, you will probably have to collect and/or analyize data then use this to support decisions that will affect your clients and community. The skills in this class will help you do this in a way that is transparent and reproducable. We are going to focus on two things this semester 1) data cleaning and visualization, and 2) developing numerical models. Historically computational methods has focused on algorithms to solve numerical integration and optimization problems. We will do some of this over the course of the semester but in practice many of you will never actually need to write a forward-difference solver, instead relying on libraries and packages that are already developed. This historically approach also ignores the new developments in data analysis workflows that have relatively recently come into common practice. 0.1 Other references There are lots of excellent references on R and other topics we’ll be covering this semester but some that you might want to pay special attention to are: Venables, WN, DM Smith, and the R Core Team, An Introduction to R, [R, version 4.0.2 (2020-06-22)], https://cran.r-project.org/doc/manuals/r-release/R-intro.pdf Intro to R is a short classic that is updated with each major release of R. Want the basics in a short format? Go here. Michonneau, F, A Fournier, and others, Data Carpentry: Data Analysis and Visualization in R for Ecologists, https://datacarpentry.org/R-ecology-lesson/ Lesson plans for the data carpentry R workshop are an excellent on-ramp to learning R. We’ll be going back and forth in these lessons over the semester. These can be an excellent refresher or a way to peak head. Hadley Wickham, Advanced R, 2nd edition (2019). https://adv-r.hadley.nz/ (ISBN-13: 978-0815384571) Advanced R is the go to book when you want to go deeper. If you want to know why something is the way it is in R this book probably has the answer, but it’s not always beginner friendly. "],
["r-and-rstudio-set-up.html", "1 R and RStudio set up 1.1 Windows install 1.2 macOS install 1.3 Linux 1.4 R libraries", " 1 R and RStudio set up R and RStudio are separate downloads and installations. R is the underlying statistical computing environment, but using R alone is no fun. RStudio is a graphical integrated development environment (IDE) that makes using R much easier and more interactive. You need to install R before you install RStudio. These instructions are adaptation from Setup for R workshops - Ecology Workshop original work licensed under CC-BY 4.0 2018–2019 by The Carpentries 1.1 Windows install Download R from the CRAN. Run the .exe file that was just downloaded Go to the RStudio download page Under Installers select RStudio x.yy.zzz - Windows Vista/7/8/10 (where x, y, and z represent version numbers) Double click the file to install it Once it’s installed, open RStudio to make sure it works and you don’t get any error messages. 1.2 macOS install Download R from the CRAN. Select the .pkg file for the latest R version Double click on the downloaded file to install R It is also a good idea to install XQuartz (needed by some packages) Go to the RStudio download page Under Installers select RStudio x.yy.zzz - Mac OS X 10.6+ (64-bit) (where x, y, and z represent version numbers) Double click the file to install RStudio Once it’s installed, open RStudio to make sure it works and you don’t get any error messages. 1.3 Linux Follow the instructions for your distribution from CRAN, they provide information to get the most recent version of R for common distributions. - For most distributions, you could use your package manager (e.g., for Debian/Ubuntu run sudo apt-get install r-base, and for Fedora sudo yum install R), but we don’t recommend this approach as the versions provided by this are usually out of date. In any case, make sure you have at least R 3.5.1. Go to the RStudio download page Under Installers select the version that matches your distribution, and install it with your preferred method (e.g., with Debian/Ubuntu sudo dpkg -i rstudio-x.yy.zzz-amd64.deb at the terminal). Once it’s installed, open RStudio to make sure it works and you don’t get any error messages. 1.4 R libraries After you install RStudio we will be working with a number of libraries this semester but the two we will focus on are tidyverse and deSolve. #install.packages(c(&#39;tidyverse&#39;, &#39;deSolve&#39;), dependencies = TRUE) #install these libraries library(tidyverse) # clean up data and plot stuff library(deSolve) #ODE solver for numerical models "],
["folder-organization.html", "2 Folder organization", " 2 Folder organization In general your files on your computer should be organized in some way that helps you find things. One thing that many people find useful is to seperate their personal and professional files into two top level directories. ~ |- Personal |- Photos |- Money |- Taxes |- Reciepts |- Professional |- 2020SpringClasses |- ComputationalMethods |- Notes |- Homework |- Homework01 |- Labs |- OldClasses If your files don’t look like this that’s ok. How you organize your computer is a very personal decision and you will probably change this multiple times over your life, but you should organize it in some way. Directories like Downloads or Temp are designed for temporary storage and should not be a permanent home for your files. Especially with Temp directories, your operating sytem or other programs on your computer could delete the files in these diretories to free up space! For this class each assignment should be in it’s own folder. This assignment folder should be zip-ed and submitted as a single upload to the course website. You should point a new Rproject session to that folder to ensure that the working directory of your Rmarkdown documents matches that of your Console. Each assignment folder should have two daughter folders: R/ and data/. All *.R files should go in the R/ folder and all data files (typically *.csv) should go in the data/ file. Each assignment should have a single primary Rmarkdown document that should be located at the top level of the assignment folder as well as it’s knit-ed html. For example, homework 1’s folder might look something like this: Homework01 |-Homework01.html |-Homework01.Rmd |-Homework01.Rproj |-data |-exampleData01.csv |-exampleData02.csv |-R |-helloWorld.R "],
["basic-programming-in-r.html", "3 Basic programming in R 3.1 R console, R-scripts, and Rmarkdown 3.2 Data types 3.3 Notation 3.4 Variables 3.5 Data structures 3.6 Indexing 3.7 Functions", " 3 Basic programming in R We are using R to develope our data workflows. R is a powerful opensource tool that will allow you to manipulate data and simulations in a way that is traceable and reproducable. R is not a general purpose programing language. R is not for production code, it’s been known to develop instabilities with large userbases. If your data is so large that you can not load it into memory, you probably do not want to use R. R is not a ‘fast’ language, in general well optimized C++ or Fortran code will run faster then R. R is a Turing complete programming language. Designed to run statistical test orginally, R creates high quality graphics and visulaizations. R is a common choice for people who need a programming language to run statistical computing and visualizations, but it is not the only laugage out there. Python is a more general purpose language that has been expanding it’s graphical capiblities. Matlab is a common choice in engineering due to it’s differental equation solvers. In the end R, Python, and Matlab can all be used in data analysis and you should use the language that is most prevolent in your community. For this class we are sticking with R. 3.1 R console, R-scripts, and Rmarkdown When you first open R markdown you will see three panels. On your left you will see a panel called ‘Console’, with several tabs under it. The upper right will have a panel called ‘Environment’, with several other tabs. And the lower right will have a panel called ‘Files’, with several tabs under it. [[TODO fill in RStudio walk through]] 3.2 Data types R has three basic data types: logical, numeric, and character. Functions are also treated by R as a fundimental data type but we will talk about them later. All numbers and characters in digital computers are reprented as a series of 1’s and 0’s or TRUE’s and FALSE’s using binary numbers which are logical data types. We’ll talk more about this connection in another section. 3.2.1 Logical data types Logical data types or booleans are the most basic and are either TRUE or FALSE. These data types are used extenstively to index arrays and lists as well as in if-statements. A Logical data type is the foundation for digital computing. At their most basic every datum in a computer is represented as a series of TRUE and FALSE. Logical values can be manipulated using boolean operations that include not (!), and (&amp;), as well as or (|). These behave about as you would expect them to: #not !TRUE ## [1] FALSE !FALSE ## [1] TRUE #and TRUE &amp; TRUE ## [1] TRUE TRUE &amp; FALSE ## [1] FALSE #or TRUE | TRUE ## [1] TRUE TRUE | FALSE ## [1] TRUE #idenity TRUE == TRUE ## [1] TRUE FALSE == TRUE ## [1] FALSE FALSE == FALSE ## [1] TRUE They can also behave as numerical values where FALSE evaluates to 0 and TRUE evaluates to 1 or greater then 0. TRUE + TRUE ## [1] 2 FALSE * TRUE ## [1] 0 Notice that the class of this changes when you force them to act as numerical values class(TRUE) ## [1] &quot;logical&quot; class(TRUE+TRUE) ## [1] &quot;integer&quot; 3.2.2 Numerical data types Numerical data types are numbers. These can be whole numbers, also called integers, like 1 or decimal numbers like 2.3. If you’ve worked in other programming languages you might recall that integers and doubles or floats behave very differently, but R treats them all as numerics and will generally like any calculator that you’ve used. #addition 1+2 ## [1] 3 #multiplication 3*4 ## [1] 12 #subtraction 5-8 ## [1] -3 #division 5/3 ## [1] 1.666667 #exponent 3^2 ## [1] 9 #log (base e) log(2) ## [1] 0.6931472 #e^x exp(2) ## [1] 7.389056 3.2.3 Characters character is the final fundimental data type in R. These include both alphanumerics like 12ad but also special chactures like $#@_. Characters in R are defined using a set of single (’‘) or double quotes (&quot;&quot;). Since we think of character as a single letter or digit it can be awkward to talk about sets of characters using the character but R has no such grammer problems. Internally R does not care if it is a single letter or a copy of the Declaration of Independence, they are both character data types. Us poor humans are left plurizing a set of characters as either ’characters’ or ‘strings’, but this is a reflection on our grammer not how they are represented by R. Characters can be pushed together using the function paste. R also has a robust regular expression library which can match specified character patterns, sort of like a generalized search function in a text editor. #a character example &#39;hi!&#39; ## [1] &quot;hi!&quot; #making a single character string paste(&quot;hello&quot;, &#39;world&#39;) ## [1] &quot;hello world&quot; #subsetting a string substr(&#39;Hello world!&#39;, start = 1, stop = 5) ## [1] &quot;Hello&quot; #cryptic preview of a regular expression grepl(&#39;\\\\d&#39;, &#39;1231&#39;) ## [1] TRUE 3.3 Notation 3.3.1 Infix notation 3.3.2 Postfix notation 3.3.3 Prefix notation 3.4 Variables In addition to using the console like a calcuator we can store the results in variables (similar to objects in other langauges). We don’t have to do anything before hand to formally initalize the variable and R has no problem switching data types that are stored in a variable. This is called a ‘weakly typed’ language and is generally not considered a good thing because it means sometimes variables are not what you expect them to be. But generally, for short analysis, this is not a huge issue for us. The assignment operator ‘&lt;-’ is used to assign the value 2 to the varaible a below. Note that R will do this silently without giving you any output to the console window unless it runs into trouble. a &lt;- 2 a ## [1] 2 When you call a variable like a + 3 the variable is not modified unless you explicitly assign the output of that operator back to the variable. For example a &lt;- 2 a + 3 ## [1] 5 a ## [1] 2 a &lt;- a + 3 a ## [1] 5 Variable names must start with an alphabet character but can contain numbers or _. They can not contain other special characters like .*^&amp;!@. There are several guideline other about what makes a good variable name and you should read the class style guide to find out what is expected in this class! 3.4.1 A brief history of the assignment operator Why the funky assigment operator ‘&lt;-’, why not just use ‘=’? I’m glad you asked! The answer is mostly historical reasons at this point. First programming languages are almost never created from nothing, they are almost all modifications of pervious programming languages. R was developed from S which was developed from several languages including APL. APL was developed to be used with a very specific keyboard that had a dedicated arrow key to produce ‘&lt;-’. So when ‘&lt;-’ was proposed it was no more key strokes then using any other character. So why not =? Well, = was being used for testing equivalancy in many languages and people didn’t want programmers to get confused between testing if two variables were the same value and assigning on value to another. Of course R went and used == for equivalancy, and enough people complained that eventually = was introduced into the lanaguage for assignment later… sort of. While = will work to assign values to variables it has some very odd side effects that makes it a questional choice in many cases. Instead R typically uses = to assign value to input variables in function calls. Which is not confusing at all… no of course it’s confusing! What’s important to remember for now is that you should use &lt;- to assign values to variables, = to assing value to function arguments, and be aware that some folks might use = to assign values to variables (but you never would!). There are reasons for all of these that has to do with the historical development of R as a programming language that is more detail then we really care about right now. 3.4.2 Factors factors are integers disguised as characters and can be a pretty nasty surpirse if you aren’t expecting them. Factors represent categorical variables, for example animals can be either ‘reptile’ or ‘mammal’. To save memory space, R has factors which assign each category an integer and then will write that integer to memory instead of the character strings. Sometimes that means R will treat factors as an integer numeric and sometimes it will treat it as a character. Right now you should just be aware that there are these funny things called ‘factors’ and double check that they are doing what you think they are when you use them. factor(c(&#39;reptile&#39;, &#39;mammal&#39;, &#39;mammal&#39;, &#39;reptile&#39;), levels = c(&#39;reptile&#39;, &#39;mammal&#39;)) ## [1] reptile mammal mammal reptile ## Levels: reptile mammal factor(c(&#39;reptile&#39;, &#39;mammal&#39;, &#39;mammal&#39;, &#39;reptile&#39;), levels = c(&#39;mammal&#39;, &#39;reptile&#39;)) ## [1] reptile mammal mammal reptile ## Levels: mammal reptile 3.5 Data structures There are two primary data structures in R: arrays and list. Lists however are used as the basis for several other data structures that we will commonly use including data.frame and tibble 3.5.1 Arrays Arrays are ordered groups of the same data type. You can think of these as N-dimentional matrices. A vector is a special array that has only one dimention. Vectors are used all the time in R to construct more complicated data structures. You use the c(...) to construct a vector and the : notation to create a vector of sequential numbers. In general, any operation you apply to a data type is applied element by element to an array of that data type myVector &lt;- c(1, 3, 4, 1) myVector ## [1] 1 3 4 1 myVector + 1 ## [1] 2 4 5 2 1:5 ## [1] 1 2 3 4 5 To create an array you need to pass the array function the values you are populating the array with and the dimentions of the array. Note that the array is populated by row first and then by column. array(c(1,3,5,7), dim=c(2,2)) ## [,1] [,2] ## [1,] 1 5 ## [2,] 3 7 3.5.2 Lists A list is a named group of data types that do not have to be the same. While a list can be unnamed, it is generally a bad idea. You can also have a list of lists. As a general rule you can not apply operations expecting a specific data type to a list object. You can get or set the names of the elemetns of a list using the function names(...). Notice that you use = to assign names to each element of a list. #a list of mixed type, including a list of a list list(a=c(1,2), b=&#39;cat&#39;, d=13, w=list(a=&#39;dog&#39;, b=c(2,3,4,1))) ## $a ## [1] 1 2 ## ## $b ## [1] &quot;cat&quot; ## ## $d ## [1] 13 ## ## $w ## $w$a ## [1] &quot;dog&quot; ## ## $w$b ## [1] 2 3 4 1 data_ls &lt;- list(a=1:4, b=&#39;cat&#39;) data_ls ## $a ## [1] 1 2 3 4 ## ## $b ## [1] &quot;cat&quot; names(data_ls) ## [1] &quot;a&quot; &quot;b&quot; names(data_ls) &lt;- c(&#39;count&#39;, &#39;animal&#39;) data_ls ## $count ## [1] 1 2 3 4 ## ## $animal ## [1] &quot;cat&quot; 3.5.3 data.frame A data.frame is a list where each element is the same length. This is very useful in representing data that is in a table form. The colums of a data.frame are associated with the names. data_df &lt;- data.frame(count = c(1,1,2,2,3), pet = c(&#39;farret&#39;, &#39;fish&#39;, &#39;bird&#39;, &#39;dog&#39;, &#39;cat&#39;)) data_df ## count pet ## 1 1 farret ## 2 1 fish ## 3 2 bird ## 4 2 dog ## 5 3 cat 3.6 Indexing Accessing specific parts of a data structure is frequently called indexing. 3.6.1 Named reference Lists have names that can be used to access each element. data_ls &lt;- list(a=c(1,2), b=&#39;cat&#39;, d=13, w=list(a=&#39;dog&#39;, b=c(2,3,4,1))) data_ls$a ## [1] 1 2 data_ls$w ## $a ## [1] &quot;dog&quot; ## ## $b ## [1] 2 3 4 1 3.6.2 Square breaket notation Both lists and arrays can be accessed using a position reference using []. data_ls &lt;- list(a=c(1,2), b=&#39;cat&#39;, d=13, w=list(a=&#39;dog&#39;, b=c(2,3,4,1))) data_ls[1] ## $a ## [1] 1 2 data_ls[2:3] ## $b ## [1] &quot;cat&quot; ## ## $d ## [1] 13 myArray &lt;- array(c(1,3,5,7), dim=c(2,2)) myArray[3] ## [1] 5 myArray[c(1,4)] ## [1] 1 7 A list can be further simplified using [[]]. It is considered simplified because it will strip away the outside list. Unline for the [] option, it often doesn’t make much sense to use the [[]] with more then one index. data_ls &lt;- list(a=c(1,2), b=&#39;cat&#39;, d=13, w=list(a=&#39;dog&#39;, b=c(2,3,4,1))) data_ls[[1]] ## [1] 1 2 Finally multiple demention arrays can also be accessed using a [,...] notation. Keep in mind that R is a row first reference. You can leave one of the sides of the , blank in this usage of the square breaket notation to access all the entries in that dimention. myArray &lt;- array(c(1,3,5,7), dim=c(2,2)) myArray ## [,1] [,2] ## [1,] 1 5 ## [2,] 3 7 #pull the second row, first column. myArray[2,1] ## [1] 3 #pull all the rows in column 1 myArray[,1] ## [1] 1 3 3.7 Functions Functions are a collection of commands with an input and an output. Anytime you find yourself copying code multiple times, that’s a pretty good indication that it should be in a function. #create a funciton myFunction &lt;- function(whom){ ans &lt;- paste(&#39;Hello&#39;, whom) #create a new variable using the input whome return(ans) #return the new variable as the output of the function } #call a function myFunction(whom = &#39;world&#39;) ## [1] &quot;Hello world&quot; There are four main parts of a function declaration: name, inputs, body, and output. Let’s consider the above function myFunction. We start by assigning a varaiable named myFunction, just like assigning a basic data type or data structure you use the assign operator. A function is considered a basic data type by R, which makes it a funcitonal programing language (as opposed to object-oriented programming languages where functions are associated with more complicated ‘objects’). Next you call the function function and specify the inputs to your new function. These inputs are essencially promisses. You are promissing that you will provide a variable that the function can refer to on execution when you call it. Then you define the body of the function by enclosing lines of code with a set of curly brackets {...}. Generally, but not always, the code in the body takes the input promised to the function and does something with it, in this example it adds the word ‘Hello’ to the start. Finally, you give the caller of the function the output using the return function. If you don’t specify what a function should return, R will try to guess. This can lead to unexpected behavior so you should specify what your function returns, in this example it’s the variable that we created called ans. After you have created a function you can now call it using the function name, followed by an open paren (, assigned input values using the =, and then a close paren ). 3.7.1 Developing a function When you are first developing a function it often makes sense to comment out everything but the body of a function and explicitly define an example input. Below there are two examples of the development version and the final version of the same function. Be sure to comment out your development case! Otherwise you’ll re-assign the input variable to a ‘hard coded’ value every single time you call the function, something that you almost never want to do! ####Development phase #calcClassGrade &lt;- function(grades_arr){ grades_arr &lt;- c(50, 23, 90, 98, 85) #the final grade is the mean of grades less then the min (ie drop the lowest grade) ans &lt;- mean(grades_arr[grades_arr &gt; min(grades_arr)]) #ans should be 80.75 for the test case # return(ans) #} ####Final phase calcClassGrade &lt;- function(grades_arr){ #grades_arr &lt;- c(50, 23, 90, 98, 85) #the final grade is the mean of grades less then the min (ie drop the lowest grade) ans &lt;- mean(grades_arr[grades_arr &gt; min(grades_arr)]) #ans should be 80.75 for the test case return(ans) } "],
["style-guide.html", "4 Style Guide 4.1 File names 4.2 Variable and function names 4.3 Comments 4.4 Functions 4.5 Indentation 4.6 Line breaks 4.7 Whitespace 4.8 Rmarkdown documents", " 4 Style Guide Writing code is not just to give instructions to a computer. It’s also to document your analysis for future users (often yourself!). Code can be perfectly fine syntatically and absolutely impossible to read as a human. You should strive for code that both executes AND is human readable. To help people read code there are certain styles conventions that have emerged. In R the tidyverse-conventions are fairly popular in the R community: Wickham, H. “Tidyverse style guide”. (2020) https://style.tidyverse.org/. 4.1 File names File names that are R-scripts should be meaningful and end in .R. Files that are markdown should end in .Rmd. Avoid using special characters and spaces in file names - stick with numbers, letters, and _. 4.2 Variable and function names Variable and function names should use only letters, numbers, and . Use underscores () (so called snake case) to separate words within a name or upperAndLower cases (so called camel case). Variable names should start with a lower case letter. Generally, variable names should be nouns and function names should be verbs. Strive for names that are concise and meaningful (this is not easy!). Where possible, avoid re-using names of common functions and variables. This will cause confusion for the readers of your code. 4.3 Comments Comments should explain what a line of code does and/or why we want to do this. Comments should be a balance of complete and brief, though for this class err on the side of verbose. Comments that explain groups of lines or entire functions should be complete sentences and on their own line. Comments that explain groups of lines should be preceded by a blank line and the relevant code should be followed by a blank line z &lt;- 0 #This is an multiline example, that explains we are going to do something to x. x &lt;- 0 x &lt;- x*8 x &lt;- x/1 y &lt;- 14 Comments that expline single lines of code may appear after that line and can be incomplete sentences. Single line comments may also precede the code, but if they do they should be treated as comments on multiline code (see above). x &lt;- x + 3 #add the measurement offset to x #Below we add the measurement offset to y. y &lt;- y + 3 z &lt;- mean(x, y) 4.4 Functions All functions should explicitly specify a return value. 4.5 Indentation Lines of code inside of { } should be indented. A line inside multiple { } should be indented once per { }. doSomething &lt;- function(x, y){ x &lt;- x * 3.1415926 if(y &lt; 0){ y &lt;- abs(y * x) } return(y * x) } 4.6 Line breaks Lines that are longer then very long (&gt;80-characters) should be broken up if possible. If a line breaks up a function, the arguments of that function should align. do_something(argument1 = 1, argument2 = &#39;as I said earlier&#39;, argument3 = c(1,2,3,4,5)) 4.7 Whitespace In general whitespace is used to make code easier to read. Group lines of code that do something similar with an empty line (and maybe add a comment to the top). Use tabs and spaces to indendent commands inside { }. 4.8 Rmarkdown documents Rmd documents should use a single # for a main header and multiple # for subheaders. Problem statements should be block quoted using &gt; And the responses to the problems should appear below in plain text. ###---Style Guide Change Log---### Feb 2, 2020 - inital draft "],
["data-cleanning.html", "5 Data cleanning 5.1 File formats 5.2 Tidyverse", " 5 Data cleanning Data cleaning is the reformating and filtering of data from a ‘raw’ state to a format where you can preform analysis on it. Virtually every dataset you work with will need some form of cleaning. 5.1 File formats While there are numberous file formats out there, we are going to focus on tabular data file formats (ie data that is delivered in a table or spread sheet). These typically fall into three categories: Excel, comma seperated values and tab seperated values. 5.1.1 Excel files Excel files are frequently used as an interface to aquire data. You are probably familar with using Excel to create basic summary statistics, formulas to calculate new values, and create graphs. While Excel can be very intitutive it is difficult to get high quality graphics or create complex analysis. That being said, the vast majority of data collected is at least initalally stored in Excel files, and R can read these files just fine! library(readxl) #the library in tidyverse to read in an excel file data.df &lt;- readxl::read_excel(path = file.path(&#39;data&#39;, &#39;PrinceFish&#39;, &#39;Red drum tissue data.xlsx&#39;), #specify the file we are reading sheet = 1) #specify the sheet we want to read in One of the major issues with Excel for long term storage of data is that Excel changes their file formats and sometimes data that reads in fine with one version of Excel will not read in well with another. In theory Excel is always backwards compatable (new version will read data generated in old versions) but in practice this is not always the case. In addition Excel is not free, this means that the data stored in that formate is often not free (but R and other languages can get around this one!). A much better format to store data in is as flat text file. These file formats contain very basic character encodings (ASCII or Unicode) with a proscribed regular structure to seperate the rows and columns. Flat text files are an open file format that any of the major operating systems can read. Flat text files are also highly stable, while characters have been added to the encoding binary, it is highly unusual for any of these characters to be removed. Two of the common file formats are comma seperated values and tab seperated values 5.1.2 CSV: comma seperated values In comma seperated value files (*.csv) columns are seperated with commas ‘,’ and rows are seperated by new line or return characters (typically ‘\\n’). The data is expected to be regular, meaning that there are the same number of columns (and thus commas) in each row. Note that this means the only ‘,’ in this file format are those seperating the columns. This can be a problem when file headers or notes in the data are particularlly long and descriptive, it’s very common to need a ‘,’ somewhere for correct English. This can be expecially confusing if you are from Europe. European’s notate decmals using ‘,’ instead of ‘.’, so 3.1415926 in the US becomes 3,1415926 in the EU. This can also make reading tables of csv numbers very confusing if you are expecting the EU convention. Often times data from Europe will be in a tabular seperated value format. 5.1.3 TSV: tab seperated values In tab seperated values, also known as tab-deliminated values, ’*.tsv’ a tab character (‘\\t’) is used to seperate the columns, and rows are seperated by new line or return characters (typically ‘\\n’). As with csv files, the data is expected to be regular, meaning that there are the same number of columns (and thus ‘\\t’) in each row. Since tabs are rarely used in English grammer, there is less of an issue with header names and other annotations. However tabs read as whitespace in a file editor, making it very easy to drop a column seperator when handling the data. So there you go, flat text files are better for archives. If you are American you are probably going to use ‘,’ to seperate the columns, while Eupeans are much more likely to use tabs. Pick a side but know the context! 5.2 Tidyverse Tidyverse is a library of libraries. What makes tidyverse different from other libraries, and particuarlly useful for us, is this collection of libraries is particarlly focused on data cleaning. There is also a syntactic shift in how functions are handled in piping. 5.2.1 Piping Pipes in R are denoted using %&gt;% and are in the magrittr library of the tidyverse. This infix notation takes the output from the left hand side function and passes it as the input to the first argument on the right hand side function. This allows you to break up long nested functions and construct data analysis pipelines incramentally. In general, your first line will be a data frame in most piping sequences. library(magrittr) ## ## Attaching package: &#39;magrittr&#39; ## The following object is masked from &#39;package:purrr&#39;: ## ## set_names ## The following object is masked from &#39;package:tidyr&#39;: ## ## extract #A trivial example data.df[,4:5] %&gt;% summary() ## Age (years) Total Length (inches) ## Min. : 0 Min. :10.0 ## 1st Qu.: 0 1st Qu.:11.0 ## Median : 1 Median :21.8 ## Mean : 5 Mean :23.5 ## 3rd Qu.: 6 3rd Qu.:36.1 ## Max. :29 Max. :43.5 #...is the same as... summary(data.df[,4:5]) ## Age (years) Total Length (inches) ## Min. : 0 Min. :10.0 ## 1st Qu.: 0 1st Qu.:11.0 ## Median : 1 Median :21.8 ## Mean : 5 Mean :23.5 ## 3rd Qu.: 6 3rd Qu.:36.1 ## Max. :29 Max. :43.5 5.2.2 Mutate, select, and filter Just like with base R, there are functions in the dplyr library in tidyverse that will subset a data frame and create new columns. 5.2.2.1 Mutate mutate creates or modifies a new column in a data frame. #temp1 is the same as temp2 in this example temp1 &lt;- data.frame(myFirst = 1:3, mySecond = 3:1) %&gt;% mutate(myProduct = myFirst/mySecond) temp2 &lt;- data.frame(myFirst = 1:3, mySecond = 3:1) temp2$myProduct &lt;- temp2$myFirst/temp2$mySecond You do not refure to the columns of the data frame with the $ notation when you are inside a tidyverse function. The function will evaluate within the context of the parent data frame, so you just need to refer to it by column name. When we talk about the group_by function next this will become clear why this is a bad idea. Take a moment and think about why the following does not run. ##does not run temp1 &lt;- data.frame(myFirst = 1:3) %&gt;% mutate(myProduct = myFirst/mySecond, mySecond = 3:1) #does run but is a bad idea temp2 &lt;- data.frame(myFirst = 1:3) %&gt;% mutate(mySecond = 3:1, myProduct = myFirst/mySecond) The mutate function in temp1 calls on a column before it is created! Just like you can’t refer to a variable becore you initalize it, you can not use a column until it’s created. While temp2 will technically run, it’s a bad idea to both create/modify and use a function in the same mutate call. 5.2.2.2 Select select returns specified columns. temp1 &lt;- data.frame(myFirst = 1:3, mySecond = 3:1) %&gt;% mutate(myProduct = myFirst/mySecond) %&gt;% select(mySecond, myProduct) temp2 &lt;- data.frame(myFirst = 1:3, mySecond = 3:1) temp2$myProduct &lt;- temp2$myFirst/temp2$mySecond #similar to mutate temp2 &lt;- temp2[,c(&#39;mySecond&#39;, &#39;myProduct&#39;)] #similar to select Select is useful primarily because it’s difficult to chain the square bracket column select notations. You can also use pattern matching to select columns with names that match particular patterns. See ?dplyr::select for more details. 5.2.2.3 Filter filter will only return rows that match specific criteria. temp1 &lt;- data.frame(myFirst = 1:3, mySecond = 3:1) %&gt;% mutate(myProduct = myFirst/mySecond) %&gt;% select(mySecond, myProduct) %&gt;% filter(mySecond == 0) temp2 &lt;- data.frame(myFirst = 1:3, mySecond = 3:1) temp2$myProduct &lt;- temp2$myFirst/temp2$mySecond #similar to mutate temp2 &lt;- temp2[,c(&#39;mySecond&#39;, &#39;myProduct&#39;)] #similar to select temp2 &lt;- temp2[temp2$mySecond == 0] #similar to filter Filter will accept multiple arguments and treat them as an ‘and’ statement. 5.2.3 Group by and summarize Often in an analysis we want to know the summary statistics are between groups within the data. For example, if we want to count the number of fish of each sex in our Excel data file. We first need to declare what our groups are using group_by data.df &lt;- read_excel(path = file.path(&#39;data&#39;, &#39;PrinceFish&#39;, &#39;Red drum tissue data.xlsx&#39;), #specify the file we are reading sheet = 1) #specify the sheet we want to read in str(data.df) ## tibble [15 × 13] (S3: tbl_df/tbl/data.frame) ## $ Sample : chr [1:15] &quot;Prince 1&quot; &quot;Prince 2&quot; &quot;Prince 3&quot; &quot;Prince 4&quot; ... ## $ Sample ID : chr [1:15] &quot;W.E -1&quot; &quot;W.E -2&quot; &quot;W.E -3&quot; &quot;W.E -4&quot; ... ## $ Species : chr [1:15] &quot;Sciaenops ocellatus&quot; &quot;Sciaenops ocellatus&quot; &quot;Sciaenops ocellatus&quot; &quot;Sciaenops ocellatus&quot; ... ## $ Age (years) : num [1:15] 29 10 6 6 19 1 1 1 1 1 ... ## $ Total Length (inches) : num [1:15] 43.5 36 36.2 36.5 39 23 20 21.8 21.5 22.4 ... ## $ Total Fish Weight (lbs) : num [1:15] 27.5 14.5 15.3 14.1 19.6 ... ## $ Sex (females are post spawn) : chr [1:15] &quot;Female&quot; &quot;Male&quot; &quot;Male&quot; &quot;Female&quot; ... ## $ d15N (permil, vs AIR) : num [1:15] 13.7 12.6 14 14 13.9 ... ## $ d13C (permil, vs VPDB) : num [1:15] -17.4 -16.9 -17.5 -17.9 -17.1 ... ## $ Lipid normalized PCB (ng/g ww) - Brain : num [1:15] 8236 3849 12479 8710 10435 ... ## $ Lipid normalized PCB (ng/g ww) - Kidney: num [1:15] 22610 32176 85346 44712 122537 ... ## $ Lipid normalized PCB (ng/g ww) - Liver : num [1:15] 19229 43376 11988 32601 49968 ... ## $ Lipid normalized PCB (ng/g ww) - Filet : num [1:15] 6064 3896 8307 5180 5859 ... data.df &lt;- data.df %&gt;% group_by(`Sex (females are post spawn)`) #note the &#39;funny&#39; single back ticks to refer to the column name #we have to do this because the column names have spaces and other special characters in them. str(data.df) ## tibble [15 × 13] (S3: grouped_df/tbl_df/tbl/data.frame) ## $ Sample : chr [1:15] &quot;Prince 1&quot; &quot;Prince 2&quot; &quot;Prince 3&quot; &quot;Prince 4&quot; ... ## $ Sample ID : chr [1:15] &quot;W.E -1&quot; &quot;W.E -2&quot; &quot;W.E -3&quot; &quot;W.E -4&quot; ... ## $ Species : chr [1:15] &quot;Sciaenops ocellatus&quot; &quot;Sciaenops ocellatus&quot; &quot;Sciaenops ocellatus&quot; &quot;Sciaenops ocellatus&quot; ... ## $ Age (years) : num [1:15] 29 10 6 6 19 1 1 1 1 1 ... ## $ Total Length (inches) : num [1:15] 43.5 36 36.2 36.5 39 23 20 21.8 21.5 22.4 ... ## $ Total Fish Weight (lbs) : num [1:15] 27.5 14.5 15.3 14.1 19.6 ... ## $ Sex (females are post spawn) : chr [1:15] &quot;Female&quot; &quot;Male&quot; &quot;Male&quot; &quot;Female&quot; ... ## $ d15N (permil, vs AIR) : num [1:15] 13.7 12.6 14 14 13.9 ... ## $ d13C (permil, vs VPDB) : num [1:15] -17.4 -16.9 -17.5 -17.9 -17.1 ... ## $ Lipid normalized PCB (ng/g ww) - Brain : num [1:15] 8236 3849 12479 8710 10435 ... ## $ Lipid normalized PCB (ng/g ww) - Kidney: num [1:15] 22610 32176 85346 44712 122537 ... ## $ Lipid normalized PCB (ng/g ww) - Liver : num [1:15] 19229 43376 11988 32601 49968 ... ## $ Lipid normalized PCB (ng/g ww) - Filet : num [1:15] 6064 3896 8307 5180 5859 ... ## - attr(*, &quot;groups&quot;)= tibble [3 × 2] (S3: tbl_df/tbl/data.frame) ## ..$ Sex (females are post spawn): chr [1:3] &quot;Female&quot; &quot;Male&quot; &quot;N/A&quot; ## ..$ .rows : list&lt;int&gt; [1:3] ## .. ..$ : int [1:2] 1 4 ## .. ..$ : int [1:3] 2 3 5 ## .. ..$ : int [1:10] 6 7 8 9 10 11 12 13 14 15 ## .. ..@ ptype: int(0) ## ..- attr(*, &quot;.drop&quot;)= logi TRUE Note that group_by didn’t chance any of the values in the data frame. Instead it create a new attribute called “groups” that reflected the column ‘Sex (females are post spawn)’. To get the average across this grouping you need to call the function summerize data.df &lt;- read_excel(path = file.path(&#39;data&#39;, &#39;PrinceFish&#39;, &#39;Red drum tissue data.xlsx&#39;), #specify the file we are reading sheet = 1) %&gt;% group_by(`Sex (females are post spawn)`) %&gt;% summarize(meanWeight = mean(`Total Fish Weight (lbs)`), meanAge = mean(`Age (years)`)) ## `summarise()` ungrouping output (override with `.groups` argument) data.df ## # A tibble: 3 x 3 ## `Sex (females are post spawn)` meanWeight meanAge ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Female 20.8 17.5 ## 2 Male 16.4 11.7 ## 3 N/A 1.79 0.5 5.2.4 Wide to long and back again (pivot_longer vs pivot_wider) In general there are two common ways to structure a data table: wide and long. Wide data has one row for each sample and several columns for each measurement. This is probably very similar to what you’ve worked with in the past when you’ve taken multiple measurements of a simple sample or site. This format is very easy for humans to interact with a cross check values during data entry. Below is an example of a wide data format site MAT MAP Gainesville, FL 68.7 52.0 Lewiston, ME 45.1 44.9 Richland, WA 52.9 7.6 Irvine, CA 63.5 14.4 A long data formate has one row for each measurement or observation. This formate is easier for computers to aggregate and manipuate (think about how you wuold apply group_by to calculate the overall mean of the MAT). You will rarely see this format for human entry. Below is the same data in a long data format site variable value Gainesville, FL MAT 68.7 Gainesville, FL MAP 52.0 Lewiston, ME MAT 45.1 Lewiston, ME MAP 45.1 Richland, WA MAT 52.9 Richland, WA MAP 7.6 Irvine, CA MAT 63.5 Irvine, CA MAP 14.4 In both formates there is usual a small set of columns that identify what is being measured and a second set of columns associated with the measurements themselves. The columns that are associated with the identify of the object of interest are often called the ‘id’ columns, and in the above example this is the site column. We can move between the wide and long formats using the pivot functions. climateData &lt;- tibble::tribble(~site, ~MAT , ~MAP , &#39;Gainesville, FL&#39; , 68.7 , 52.0, &#39;Lewiston, ME&#39; , 45.1 , 44.9, &#39;Richland, WA&#39; , 52.9 , 7.6, &#39;Irvine, CA&#39;, 63.5 , 14.4) #tribble is a useful way to code in data by row climateData ## # A tibble: 4 x 3 ## site MAT MAP ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Gainesville, FL 68.7 52 ## 2 Lewiston, ME 45.1 44.9 ## 3 Richland, WA 52.9 7.6 ## 4 Irvine, CA 63.5 14.4 climateData_long &lt;- climateData %&gt;% pivot_longer(cols=c(&#39;MAT&#39;, &#39;MAP&#39;)) climateData_long ## # A tibble: 8 x 3 ## site name value ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Gainesville, FL MAT 68.7 ## 2 Gainesville, FL MAP 52 ## 3 Lewiston, ME MAT 45.1 ## 4 Lewiston, ME MAP 44.9 ## 5 Richland, WA MAT 52.9 ## 6 Richland, WA MAP 7.6 ## 7 Irvine, CA MAT 63.5 ## 8 Irvine, CA MAP 14.4 climateData_wide &lt;- climateData_long %&gt;% pivot_wider(id_cols = &#39;site&#39;) climateData_wide ## # A tibble: 4 x 3 ## site MAT MAP ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Gainesville, FL 68.7 52 ## 2 Lewiston, ME 45.1 44.9 ## 3 Richland, WA 52.9 7.6 ## 4 Irvine, CA 63.5 14.4 "],
["visualization.html", "6 Visualization 6.1 Regular expressions", " 6 Visualization Part of the tidyverse is the package ggplot2 which has so improved plots in R that we aren’t even going to talk about the basic ploting functions and will skip straight to using this package. In ggplot you start with creating a plot object associated with a specific data set. climateData &lt;- tibble::tribble(~site, ~MAT , ~MAP , &#39;Gainesville, FL&#39; , 68.7 , 52.0, &#39;Lewiston, ME&#39; , 45.1 , 44.9, &#39;Richland, WA&#39; , 52.9 , 7.6, &#39;Irvine, CA&#39;, 63.5 , 14.4) %&gt;% pivot_longer(cols=c(&#39;MAT&#39;, &#39;MAP&#39;)) ggplot(data = climateData) This creates an empty plot. You then need to add different geometries that are mapped using asthetics to the data you used to create the object. In this case we are creating a histogram. ggplot(data = climateData) + geom_histogram(mapping = aes(x = value)) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. But for our data that histogram spans two different measurements MAT and MAP. So we can wrap that in a facet to create subplots. ggplot(data = climateData) + geom_histogram(mapping = aes(x = value)) + facet_wrap(~name) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. We can also do scatter plots ggplot(data = climateData) + geom_point(mapping = aes(x=site, y=value)) + facet_wrap(~name, nrow=2) 6.1 Regular expressions There is a running joke in data science that all data is text data, so all problems are regular expressions. There is another joke that if you try to use regular expressions to solve a problem, you now have two problems. Regular expressions are extremely useful and challenging to use, but the core concept is you have a pattern you want to find in a block of text. Simple right? Regular expressions have evolved to a certain standard that is, generally, true across all programming languages, which means that what you learn here you can take with you to Python, Perl, or VBA. Each of those languages, however do have their own twist and excentricities they put on the patterns. We’ll talk about the general conventions first, then go over what R does differently, before finally covering the specific functions you can use to get started. In general, a regular experession will tell you 1) what character, 2) how many times, and 3) where. Let’s start with the what. 6.1.0.1 What characters Most characters you will work with fall loosly into four categories: digits, letters, white space, and special characters. Regular expression has special sort cuts for most of these: what character match regexp standard digits [0-9] \\d letters (plus numbers and underscore) [A-Za-z0-9_] \\w white space (including tabs) [ \\t] \\s Special characters can be matched using the \\ followed by the specific character. You can also use the [ ] to match to a set of characters and the ‘-’ notates all the interviening sequential characters. For example: ‘[acb]’ will match to either ‘a’ or ‘c’ or ‘b’. Also ‘[a-c]’ will match ‘a’ or ‘b’ or ‘c’. Note that the period ‘.’ is a wild card and will match any character. You can also use the ^ within the [ ] to say ‘not’ some character as prefix notation. 6.1.0.2 How many times Next you need to say how many times you match that character. If you leave this unspecified it will match once and only once. how many post-fix notation * zero or more times + one or more times ? zero or one times This is used as a post-fix notation, you say what character set you are matching first then you say how many times you are matching it. For example: ‘c?at’ will match both ‘cat’ and ‘bat’, but it will also match ‘attract’. Partial matches are valid matches, we are just looking for some part to match the regular expression. 6.1.0.3 Where Finally where does it match. You can anchor a regular expression to either the start or the end of a string using ‘^’ for the start and ‘$’ for the end. Yes ‘^’ gets used in two different ways in regular expressions, but it is evaluated in context. If it is the first character in the pattern, then it archors the rest of the string to the start, otherwise it’s evaluated as a negation. For example: ‘^c?at’ will still match ‘cat’ and ‘attract’ since the pattern is at the start of the string, but it will not match ‘bat’ since the ‘b’ comes before the pattern. 6.1.1 R-regexp R makes things a little tricky by doubling up on the \\ for the regexp standard notation. For example: ‘\\d’ becomes ‘\\\\d’. R also introduces ‘[: :]’ notation for the character set short hands. You don’t have to use ‘[: :]’ but if you are interested you can read more here [https://stat.ethz.ch/R-manual/R-devel/library/base/html/regex.html]](https://stat.ethz.ch/R-manual/R-devel/library/base/html/regex.html). 6.1.1.1 grepl: Does it match? grepl returns TRUE if the provided pattern matches and FALSE if it does not. This can be useful when applied to an array of characters to see which ones match a pattern and which ones don’t. grepl(&#39;^c?at&#39;, c(&#39;cat&#39;, &#39;bat&#39;, &#39;attach&#39;)) ## [1] TRUE FALSE TRUE data.df &lt;- data.frame(pet=c(&#39;cat&#39;, &#39;dog&#39;, &#39;dog&#39;, &#39;Cat&#39;), person = c(&#39;Mars&#39;, &#39;Jes&#39;, &#39;Bill&#39;, &#39;Bill&#39;)) data.df[grepl(&#39;[cC]at&#39;, data.df$pet),] #pull the rows of the cat owners ## pet person ## 1 cat Mars ## 4 Cat Bill 6.1.1.2 gsub: Find and replace gsub will match one pattern and then replace every occurance of that pattern with another string. This is often times quite useful to strip out unwanted text. gsub(&#39;[cC]at&#39;, &#39;dog&#39;, &#39;All good cats get tasty cat treats&#39;) ## [1] &quot;All good dogs get tasty dog treats&quot; gsub(&#39;\\\\s*\\\\d+$&#39;, &#39;&#39;, c(&#39;March 2&#39;, &#39;April 3&#39;, &#39;May 13&#39;, &#39;2020 Feb 29&#39;)) ## [1] &quot;March&quot; &quot;April&quot; &quot;May&quot; &quot;2020 Feb&quot; 6.1.1.3 regmatches: Find and copy Finally regmatches will pull sections of the string that match a certain pattern. Note that this could be zero or more matches so regmatches will return a list of matches. regmatches(c(&#39;March 2&#39;, &#39;April 3&#39;, &#39;May 13&#39;, &#39;2020 Feb 29&#39;), gregexpr(&#39;\\\\d+$&#39;, c(&#39;March 2&#39;, &#39;April 3&#39;, &#39;May 13&#39;, &#39;2020 Feb 29&#39;))) ## [[1]] ## [1] &quot;2&quot; ## ## [[2]] ## [1] &quot;3&quot; ## ## [[3]] ## [1] &quot;13&quot; ## ## [[4]] ## [1] &quot;29&quot; regmatches(c(&#39;March 2&#39;, &#39;April 3&#39;, &#39;May 13&#39;, &#39;2020 Feb 29&#39;), gregexpr(&#39;\\\\d+&#39;, c(&#39;March 2&#39;, &#39;April 3&#39;, &#39;May 13&#39;, &#39;2020 Feb 29&#39;))) ## [[1]] ## [1] &quot;2&quot; ## ## [[2]] ## [1] &quot;3&quot; ## ## [[3]] ## [1] &quot;13&quot; ## ## [[4]] ## [1] &quot;2020&quot; &quot;29&quot; 6.1.1.4 splits and subsets If your pattern is based on the character position instead of a regular expression you are in luck! subset takes a character set, a start index, and a stop index, then returns the trimmed character set for you. substr(c(&#39;2020-03-03&#39;, &#39;2019-04-02&#39;), 1, 4) ## [1] &quot;2020&quot; &quot;2019&quot; Other times you want to slip a string on a specific character strsplit(c(&#39;2020-03-03&#39;, &#39;2019-04-02&#39;), split = &#39;-&#39;) ## [[1]] ## [1] &quot;2020&quot; &quot;03&quot; &quot;03&quot; ## ## [[2]] ## [1] &quot;2019&quot; &quot;04&quot; &quot;02&quot; "]
]
